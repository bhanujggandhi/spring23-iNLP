{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  !nvidia-smi -L\n",
        "  google.colab.drive.mount('/content/drive/')               # For saving the model.\n",
        "  #%cd ../content/drive/SaveLocation\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625ch9AYJL1G",
        "outputId": "ec067cb0-0758-4343-a09c-ef37725c466a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5dfdc142-7fe8-17fe-b6f6-0b59ab820e47)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "hywZ8einF8uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj_FmGXqF_HG",
        "outputId": "a48e0c1f-4d3b-4a24-9902-5d230517389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc308049150>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEg_ODBGAyE",
        "outputId": "0e81ccac-b20d-42ab-e4c4-e3350bc4462d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Ulysses - James Joyce.txt\", \"r\") as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "\n",
        "print(corpus[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnKfBmRGIvB",
        "outputId": "7ecf3f59-9f32-4164-d760-a8a86198862b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 ]\n",
            "\n",
            "Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of\n",
            "lather on which a mirror and a razor lay crossed. A yellow\n",
            "dressinggown, ungirdled, was sustained gently behind him on the mild\n",
            "morning air. He held the bowl aloft and intoned:\n",
            "\n",
            "—_Introibo ad altare Dei_.\n",
            "\n",
            "Halted, he peered down the dark winding stairs and called out coarsely:\n",
            "\n",
            "—Come up, Kinch! Come up, you fearful jesuit!\n",
            "\n",
            "Solemnly he came forward and mounted the round gunrest. He faced about\n",
            "and blessed gravely thrice the tower, the surrounding land and the\n",
            "awaking mountains. Then, catching sight of Stephen Dedalus, he bent\n",
            "towards him and made rapid crosses in the air, gurgling in his throat\n",
            "and shaking his head. Stephen Dedalus, displeased and sleepy, leaned\n",
            "his arms on the top of the staircase and looked coldly at the shaking\n",
            "gurgling face that blessed him, equine in its length, and at the light\n",
            "untonsured hair, grained and hued like pale oak.\n",
            "\n",
            "Buck Mulligan peeped an instant under the mirror and then c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer function returns clean data\n",
        "def clean_text(text):\n",
        "    import re\n",
        "    text = re.sub(\n",
        "        r'(Mr\\.|Mrs\\.|Ms\\.)[a-zA-Z]*', '<TITLE>', text)\n",
        "    text = re.sub(r'https?:\\/\\/\\S+\\b(?!\\.)?', '<URL>', text)\n",
        "    text = re.sub(r'@\\w+', '<MENTION>', text)\n",
        "    text = re.sub(r'#\\w+', '<HASHTAG>', text)\n",
        "    text = re.sub(r'\\S*[\\w\\~\\-]\\@[\\w\\~\\-]\\S*', r'<EMAIL>', text)\n",
        "\n",
        "    text = re.sub(r'([a-zA-Z]+)n[\\'’]t', r'\\1 not', text)\n",
        "    text = re.sub(r'([iI])[\\'’]m', r'\\1 am', text)\n",
        "    text = re.sub(r'([a-zA-Z]+)[\\'’]s', r'\\1 is', text)\n",
        "\n",
        "    text = re.sub(r'\\*{2,}.*?\\*{2,}', '', text, flags=re.DOTALL)\n",
        "\n",
        "    text = re.sub(r\"_(.*?)_\", r\"\\1\", text)\n",
        "    text = text.split()\n",
        "    text = \" \".join(text)\n",
        "#     text = \"<s> \" + text + \" <e>\"\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s<>.]', ' ', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "pnXpRO0kGN1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus = sent_tokenize(corpus)\n",
        "corpus = clean_text(corpus)\n",
        "# corpus[:1000]"
      ],
      "metadata": {
        "id": "L93zwjJDGP1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "corpus = corpus.split(\". \")\n",
        "for sent in corpus:\n",
        "    split = sent.split(\" \")\n",
        "    split = [s for s in split if len(s) > 0]\n",
        "    if len(split) > 0:\n",
        "      sent = \" \".join(split)\n",
        "      text.append(sent)\n",
        "\n",
        "text_len = len(text)\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO7cv4NoGSKd",
        "outputId": "9389040a-8862-4dff-8f45-3e714fcfe482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 stately plump buck mulligan came from the stairhead bearing a bowl of lather on which a mirror and a razor lay crossed',\n",
              " 'a yellow dressinggown ungirdled was sustained gently behind him on the mild morning air',\n",
              " 'he held the bowl aloft and intoned introibo ad altare dei',\n",
              " 'halted he peered down the dark winding stairs and called out coarsely come up kinch come up you fearful jesuit solemnly he came forward and mounted the round gunrest',\n",
              " 'he faced about and blessed gravely thrice the tower the surrounding land and the awaking mountains',\n",
              " 'then catching sight of stephen dedalus he bent towards him and made rapid crosses in the air gurgling in his throat and shaking his head',\n",
              " 'stephen dedalus displeased and sleepy leaned his arms on the top of the staircase and looked coldly at the shaking gurgling face that blessed him equine in its length and at the light untonsured hair grained and hued like pale oak',\n",
              " 'buck mulligan peeped an instant under the mirror and then covered the bowl smartly',\n",
              " 'back to barracks he said sternly',\n",
              " 'he added in a preacher is tone for this o dearly beloved is the genuine christine body and soul and blood and ouns',\n",
              " 'slow music please',\n",
              " 'shut your eyes gents',\n",
              " 'one moment',\n",
              " 'a little trouble about those white corpuscles',\n",
              " 'silence all',\n",
              " 'he peered sideways up and gave a long slow whistle of call then paused awhile in rapt attention his even white teeth glistening here and there with gold points',\n",
              " 'chrysostomos',\n",
              " 'two strong shrill whistles answered through the calm',\n",
              " 'thanks old chap he cried briskly',\n",
              " 'that will do nicely',\n",
              " 'switch off the current will you he skipped off the gunrest and looked gravely at his watcher gathering about his legs the loose folds of his gown',\n",
              " 'the plump shadowed face and sullen oval jowl recalled a prelate patron of arts in the middle ages',\n",
              " 'a pleasant smile broke quietly over his lips',\n",
              " 'the mockery of it he said gaily',\n",
              " 'your absurd name an ancient greek he pointed his finger in friendly jest and went over to the parapet laughing to himself',\n",
              " 'stephen dedalus stepped up followed him wearily halfway and sat down on the edge of the gunrest watching him still as he propped his mirror on the parapet dipped the brush in the bowl and lathered cheeks and neck',\n",
              " 'buck mulligan is gay voice went on',\n",
              " 'my name is absurd too malachi mulligan two dactyls',\n",
              " 'but it has a hellenic ring has not it tripping and sunny like the buck himself',\n",
              " 'we must go to athens',\n",
              " 'will you come if i can get the aunt to fork out twenty quid he laid the brush aside and laughing with delight cried will he come the jejune jesuit ceasing he began to shave with care',\n",
              " 'tell me mulligan stephen said quietly',\n",
              " 'yes my love how long is haines going to stay in this tower buck mulligan showed a shaven cheek over his right shoulder',\n",
              " 'god is not he dreadful he said frankly',\n",
              " 'a ponderous saxon',\n",
              " 'he thinks you re not a gentleman',\n",
              " 'god these bloody english bursting with money and indigestion',\n",
              " 'because he comes from oxford',\n",
              " 'you know dedalus you have the real oxford manner',\n",
              " 'he ca not make you out',\n",
              " 'o my name for you is the best kinch the knife blade',\n",
              " 'he shaved warily over his chin',\n",
              " 'he was raving all night about a black panther stephen said',\n",
              " 'where is his guncase a woful lunatic mulligan said',\n",
              " 'were you in a funk i was stephen said with energy and growing fear',\n",
              " 'out here in the dark with a man i do not know raving and moaning to himself about shooting a black panther',\n",
              " 'you saved men from drowning',\n",
              " 'i am not a hero however',\n",
              " 'if he stays on here i am off',\n",
              " 'buck mulligan frowned at the lather on his razorblade',\n",
              " 'he hopped down from his perch and began to search his trouser pockets hastily',\n",
              " 'scutter he cried thickly',\n",
              " 'he came over to the gunrest and thrusting a hand into stephen is upper pocket said lend us a loan of your noserag to wipe my razor',\n",
              " 'stephen suffered him to pull out and hold up on show by its corner a dirty crumpled handkerchief',\n",
              " 'buck mulligan wiped the razorblade neatly',\n",
              " 'then gazing over the handkerchief he said the bard is noserag a new art colour for our irish poets snotgreen',\n",
              " 'you can almost taste it ca not you he mounted to the parapet again and gazed out over dublin bay his fair oakpale hair stirring slightly',\n",
              " 'god he said quietly',\n",
              " 'is not the sea what algy calls it a great sweet mother the snotgreen sea',\n",
              " 'the scrotumtightening sea',\n",
              " '_epi oinopa ponton_',\n",
              " 'ah dedalus the greeks i must teach you',\n",
              " 'you must read them in the original',\n",
              " 'thalatta thalatta she is our great sweet mother',\n",
              " 'come and look',\n",
              " 'stephen stood up and went over to the parapet',\n",
              " 'leaning on it he looked down on the water and on the mailboat clearing the harbourmouth of kingstown',\n",
              " 'our mighty mother buck mulligan said',\n",
              " 'he turned abruptly his grey searching eyes from the sea to stephen is face',\n",
              " 'the aunt thinks you killed your mother he said',\n",
              " 'that is why she wo not let me have anything to do with you',\n",
              " 'someone killed her stephen said gloomily',\n",
              " 'you could have knelt down damn it kinch when your dying mother asked you buck mulligan said',\n",
              " 'i am hyperborean as much as you',\n",
              " 'but to think of your mother begging you with her last breath to kneel down and pray for her',\n",
              " 'and you refused',\n",
              " 'there is something sinister in you',\n",
              " 'he broke off and lathered again lightly his farther cheek',\n",
              " 'a tolerant smile curled his lips',\n",
              " 'but a lovely mummer he murmured to himself',\n",
              " 'kinch the loveliest mummer of them all he shaved evenly and with care in silence seriously',\n",
              " 'stephen an elbow rested on the jagged granite leaned his palm against his brow and gazed at the fraying edge of his shiny black coat sleeve',\n",
              " 'pain that was not yet the pain of love fretted his heart',\n",
              " 'silently in a dream she had come to him after her death her wasted body within its loose brown graveclothes giving off an odour of wax and rosewood her breath that had bent upon him mute reproachful a faint odour of wetted ashes',\n",
              " 'across the threadbare cuffedge he saw the sea hailed as a great sweet mother by the wellfed voice beside him',\n",
              " 'the ring of bay and skyline held a dull green mass of liquid',\n",
              " 'a bowl of white china had stood beside her deathbed holding the green sluggish bile which she had torn up from her rotting liver by fits of loud groaning vomiting',\n",
              " 'buck mulligan wiped again his razorblade',\n",
              " 'ah poor dogsbody he said in a kind voice',\n",
              " 'i must give you a shirt and a few noserags',\n",
              " 'how are the secondhand breeks they fit well enough stephen answered',\n",
              " 'buck mulligan attacked the hollow beneath his underlip',\n",
              " 'the mockery of it he said contentedly',\n",
              " 'secondleg they should be',\n",
              " 'god knows what poxy bowsy left them off',\n",
              " 'i have a lovely pair with a hair stripe grey',\n",
              " 'you ll look spiffing in them',\n",
              " 'i am not joking kinch',\n",
              " 'you look damn well when you re dressed',\n",
              " 'thanks stephen said']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.7*text_len)\n",
        "dev_split = int(0.15*text_len)\n",
        "\n",
        "train_data = text[:train_split]\n",
        "dev_data = text[train_split:train_split+dev_split]\n",
        "test_data = text[train_split+dev_split:]\n"
      ],
      "metadata": {
        "id": "NohCBCQ3GT2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for sent in train_data:\n",
        "    vocab.update(sent.split())\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ll0Ekx0GV9C",
        "outputId": "8aa2465f-818c-4fdc-e54a-0f89ded9f1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18691"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add(\"<unk>\")\n",
        "vocab.add(\"<eos>\")\n",
        "len(vocab)\n",
        "vocab = list(vocab)\n",
        "vocab_dict = {}\n",
        "for i, word in enumerate(vocab):\n",
        "    vocab_dict[word] = i\n",
        "    "
      ],
      "metadata": {
        "id": "gDP_27fnGX-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = {}\n",
        "for sent in text:\n",
        "    for word in sent.split():\n",
        "        if word_count.get(word) is None:\n",
        "            word_count[word] = 1\n",
        "        else:\n",
        "            word_count[word]+=1\n",
        "           "
      ],
      "metadata": {
        "id": "b1rQIwfJGaI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJN0w-GLGbqH",
        "outputId": "7829da07-f393-4832-a2e6-9226fae3894d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 90,\n",
              " 'stately': 3,\n",
              " 'plump': 19,\n",
              " 'buck': 116,\n",
              " 'mulligan': 155,\n",
              " 'came': 194,\n",
              " 'from': 1080,\n",
              " 'the': 14877,\n",
              " 'stairhead': 3,\n",
              " 'bearing': 25,\n",
              " 'a': 6425,\n",
              " 'bowl': 12,\n",
              " 'of': 8115,\n",
              " 'lather': 4,\n",
              " 'on': 2036,\n",
              " 'which': 511,\n",
              " 'mirror': 36,\n",
              " 'and': 7197,\n",
              " 'razor': 5,\n",
              " 'lay': 66,\n",
              " 'crossed.': 1,\n",
              " 'yellow': 47,\n",
              " 'dressinggown': 1,\n",
              " 'ungirdled': 2,\n",
              " 'was': 2112,\n",
              " 'sustained': 11,\n",
              " 'gently': 27,\n",
              " 'behind': 129,\n",
              " 'him': 1312,\n",
              " 'mild': 11,\n",
              " 'morning': 88,\n",
              " 'air.': 30,\n",
              " 'he': 4090,\n",
              " 'held': 60,\n",
              " 'aloft': 4,\n",
              " 'intoned': 1,\n",
              " 'introibo': 2,\n",
              " 'ad': 29,\n",
              " 'altare': 2,\n",
              " 'dei.': 1,\n",
              " 'halted': 34,\n",
              " 'peered': 11,\n",
              " 'down': 412,\n",
              " 'dark': 114,\n",
              " 'winding': 11,\n",
              " 'stairs': 14,\n",
              " 'called': 83,\n",
              " 'out': 824,\n",
              " 'coarsely': 1,\n",
              " 'come': 230,\n",
              " 'up': 728,\n",
              " 'kinch': 22,\n",
              " 'you': 1873,\n",
              " 'fearful': 2,\n",
              " 'jesuit': 9,\n",
              " 'solemnly': 6,\n",
              " 'forward': 62,\n",
              " 'mounted': 4,\n",
              " 'round': 231,\n",
              " 'gunrest.': 1,\n",
              " 'faced': 4,\n",
              " 'about': 509,\n",
              " 'blessed': 46,\n",
              " 'gravely': 12,\n",
              " 'thrice': 4,\n",
              " 'tower': 23,\n",
              " 'surrounding': 2,\n",
              " 'land': 72,\n",
              " 'awaking': 2,\n",
              " 'mountains.': 3,\n",
              " 'then': 533,\n",
              " 'catching': 1,\n",
              " 'sight': 30,\n",
              " 'stephen': 527,\n",
              " 'dedalus': 166,\n",
              " 'bent': 36,\n",
              " 'towards': 120,\n",
              " 'made': 180,\n",
              " 'rapid': 5,\n",
              " 'crosses': 3,\n",
              " 'in': 4876,\n",
              " 'air': 83,\n",
              " 'gurgling': 4,\n",
              " 'his': 3309,\n",
              " 'throat': 16,\n",
              " 'shaking': 12,\n",
              " 'head.': 38,\n",
              " 'displeased': 2,\n",
              " 'sleepy': 8,\n",
              " 'leaned': 14,\n",
              " 'arms': 76,\n",
              " 'top': 30,\n",
              " 'staircase': 12,\n",
              " 'looked': 99,\n",
              " 'coldly': 2,\n",
              " 'at': 1283,\n",
              " 'face': 185,\n",
              " 'that': 2652,\n",
              " 'equine': 4,\n",
              " 'its': 299,\n",
              " 'length': 7,\n",
              " 'light': 101,\n",
              " 'untonsured': 1,\n",
              " 'hair': 98,\n",
              " 'grained': 1,\n",
              " 'hued': 1,\n",
              " 'like': 714,\n",
              " 'pale': 18,\n",
              " 'oak.': 1,\n",
              " 'peeped': 3,\n",
              " 'an': 653,\n",
              " 'instant': 31,\n",
              " 'under': 223,\n",
              " 'covered': 20,\n",
              " 'smartly.': 2,\n",
              " 'back': 301,\n",
              " 'to': 4906,\n",
              " 'barracks': 4,\n",
              " 'said': 724,\n",
              " 'sternly.': 3,\n",
              " 'added': 28,\n",
              " 'preacher': 2,\n",
              " 'is': 3966,\n",
              " 'tone': 21,\n",
              " 'for': 1916,\n",
              " 'this': 427,\n",
              " 'o': 513,\n",
              " 'dearly': 2,\n",
              " 'beloved': 5,\n",
              " 'genuine': 7,\n",
              " 'christine': 1,\n",
              " 'body': 64,\n",
              " 'soul': 50,\n",
              " 'blood': 46,\n",
              " 'ouns.': 1,\n",
              " 'slow': 35,\n",
              " 'music': 61,\n",
              " 'please.': 11,\n",
              " 'shut': 24,\n",
              " 'your': 483,\n",
              " 'eyes': 268,\n",
              " 'gents.': 1,\n",
              " 'little': 286,\n",
              " 'trouble': 28,\n",
              " 'those': 315,\n",
              " 'white': 152,\n",
              " 'corpuscles.': 1,\n",
              " 'sideways': 20,\n",
              " 'gave': 123,\n",
              " 'long': 228,\n",
              " 'whistle': 11,\n",
              " 'call': 104,\n",
              " 'paused': 5,\n",
              " 'awhile': 9,\n",
              " 'rapt': 4,\n",
              " 'attention': 26,\n",
              " 'even': 122,\n",
              " 'teeth': 33,\n",
              " 'glistening': 6,\n",
              " 'here': 202,\n",
              " 'there': 693,\n",
              " 'with': 2496,\n",
              " 'gold': 81,\n",
              " 'points.': 11,\n",
              " 'two': 370,\n",
              " 'strong': 30,\n",
              " 'shrill': 9,\n",
              " 'whistles': 3,\n",
              " 'answered': 43,\n",
              " 'through': 242,\n",
              " 'calm.': 1,\n",
              " 'thanks': 30,\n",
              " 'old': 472,\n",
              " 'chap': 49,\n",
              " 'cried': 57,\n",
              " 'briskly.': 4,\n",
              " 'will': 331,\n",
              " 'do': 585,\n",
              " 'nicely.': 3,\n",
              " 'switch': 4,\n",
              " 'off': 332,\n",
              " 'current': 5,\n",
              " 'skipped': 2,\n",
              " 'gunrest': 3,\n",
              " 'watcher': 3,\n",
              " 'gathering': 9,\n",
              " 'legs': 25,\n",
              " 'loose': 31,\n",
              " 'folds': 5,\n",
              " 'gown.': 4,\n",
              " 'shadowed': 3,\n",
              " 'sullen': 2,\n",
              " 'oval': 8,\n",
              " 'jowl': 3,\n",
              " 'recalled': 2,\n",
              " 'prelate': 2,\n",
              " 'patron': 5,\n",
              " 'arts': 6,\n",
              " 'middle': 32,\n",
              " 'ages.': 5,\n",
              " 'pleasant': 19,\n",
              " 'smile': 32,\n",
              " 'broke': 29,\n",
              " 'quietly': 24,\n",
              " 'over': 413,\n",
              " 'lips.': 26,\n",
              " 'mockery': 7,\n",
              " 'it': 2254,\n",
              " 'gaily.': 7,\n",
              " 'absurd': 6,\n",
              " 'name': 187,\n",
              " 'ancient': 34,\n",
              " 'greek': 17,\n",
              " 'pointed': 14,\n",
              " 'finger': 29,\n",
              " 'friendly': 11,\n",
              " 'jest': 3,\n",
              " 'went': 179,\n",
              " 'parapet': 4,\n",
              " 'laughing': 41,\n",
              " 'himself.': 38,\n",
              " 'stepped': 17,\n",
              " 'followed': 51,\n",
              " 'wearily': 2,\n",
              " 'halfway': 2,\n",
              " 'sat': 40,\n",
              " 'edge': 14,\n",
              " 'watching': 21,\n",
              " 'still': 177,\n",
              " 'as': 1182,\n",
              " 'propped': 5,\n",
              " 'dipped': 5,\n",
              " 'brush': 10,\n",
              " 'lathered': 2,\n",
              " 'cheeks': 15,\n",
              " 'neck.': 10,\n",
              " 'gay': 20,\n",
              " 'voice': 154,\n",
              " 'on.': 58,\n",
              " 'my': 813,\n",
              " 'too': 323,\n",
              " 'malachi': 24,\n",
              " 'dactyls.': 1,\n",
              " 'but': 679,\n",
              " 'has': 289,\n",
              " 'hellenic': 2,\n",
              " 'ring': 26,\n",
              " 'not': 1471,\n",
              " 'tripping': 5,\n",
              " 'sunny': 4,\n",
              " 'we': 452,\n",
              " 'must': 214,\n",
              " 'go': 210,\n",
              " 'athens.': 1,\n",
              " 'if': 538,\n",
              " 'i': 2876,\n",
              " 'can': 201,\n",
              " 'get': 249,\n",
              " 'aunt': 20,\n",
              " 'fork': 10,\n",
              " 'twenty': 27,\n",
              " 'quid': 18,\n",
              " 'laid': 50,\n",
              " 'aside': 23,\n",
              " 'delight': 5,\n",
              " 'jejune': 1,\n",
              " 'ceasing': 2,\n",
              " 'began': 43,\n",
              " 'shave': 6,\n",
              " 'care.': 7,\n",
              " 'tell': 166,\n",
              " 'me': 771,\n",
              " 'quietly.': 8,\n",
              " 'yes': 242,\n",
              " 'love': 152,\n",
              " 'how': 263,\n",
              " 'haines': 59,\n",
              " 'going': 193,\n",
              " 'stay': 13,\n",
              " 'showed': 20,\n",
              " 'shaven': 5,\n",
              " 'cheek': 12,\n",
              " 'right': 176,\n",
              " 'shoulder.': 16,\n",
              " 'god': 221,\n",
              " 'dreadful': 9,\n",
              " 'frankly.': 1,\n",
              " 'ponderous': 4,\n",
              " 'saxon.': 2,\n",
              " 'thinks': 24,\n",
              " 're': 112,\n",
              " 'gentleman.': 5,\n",
              " 'these': 99,\n",
              " 'bloody': 104,\n",
              " 'english': 24,\n",
              " 'bursting': 2,\n",
              " 'money': 75,\n",
              " 'indigestion.': 1,\n",
              " 'because': 219,\n",
              " 'comes': 57,\n",
              " 'oxford.': 2,\n",
              " 'know': 287,\n",
              " 'have': 681,\n",
              " 'real': 33,\n",
              " 'oxford': 7,\n",
              " 'manner.': 3,\n",
              " 'ca': 62,\n",
              " 'make': 172,\n",
              " 'out.': 65,\n",
              " 'best': 124,\n",
              " 'knife': 20,\n",
              " 'blade.': 1,\n",
              " 'shaved': 4,\n",
              " 'warily': 3,\n",
              " 'chin.': 5,\n",
              " 'raving': 3,\n",
              " 'all': 1239,\n",
              " 'night': 191,\n",
              " 'black': 135,\n",
              " 'panther': 5,\n",
              " 'said.': 446,\n",
              " 'where': 309,\n",
              " 'guncase': 1,\n",
              " 'woful': 2,\n",
              " 'lunatic': 5,\n",
              " 'were': 509,\n",
              " 'funk': 1,\n",
              " 'energy': 3,\n",
              " 'growing': 7,\n",
              " 'fear.': 7,\n",
              " 'man': 391,\n",
              " 'moaning': 4,\n",
              " 'himself': 179,\n",
              " 'shooting': 7,\n",
              " 'panther.': 1,\n",
              " 'saved': 17,\n",
              " 'men': 130,\n",
              " 'drowning.': 2,\n",
              " 'am': 306,\n",
              " 'hero': 14,\n",
              " 'however.': 8,\n",
              " 'stays': 8,\n",
              " 'off.': 36,\n",
              " 'frowned': 9,\n",
              " 'razorblade.': 2,\n",
              " 'hopped': 1,\n",
              " 'perch': 3,\n",
              " 'search': 10,\n",
              " 'trouser': 5,\n",
              " 'pockets': 19,\n",
              " 'hastily.': 1,\n",
              " 'thickly.': 1,\n",
              " 'thrusting': 2,\n",
              " 'hand': 240,\n",
              " 'into': 327,\n",
              " 'upper': 20,\n",
              " 'pocket': 53,\n",
              " 'lend': 10,\n",
              " 'us': 216,\n",
              " 'loan': 4,\n",
              " 'noserag': 2,\n",
              " 'wipe': 6,\n",
              " 'razor.': 2,\n",
              " 'suffered': 7,\n",
              " 'pull': 19,\n",
              " 'hold': 48,\n",
              " 'show': 59,\n",
              " 'by': 1247,\n",
              " 'corner': 74,\n",
              " 'dirty': 23,\n",
              " 'crumpled': 7,\n",
              " 'handkerchief.': 4,\n",
              " 'wiped': 11,\n",
              " 'razorblade': 1,\n",
              " 'neatly.': 1,\n",
              " 'gazing': 7,\n",
              " 'handkerchief': 19,\n",
              " 'bard': 6,\n",
              " 'new': 152,\n",
              " 'art': 47,\n",
              " 'colour': 21,\n",
              " 'our': 284,\n",
              " 'irish': 108,\n",
              " 'poets': 10,\n",
              " 'snotgreen.': 1,\n",
              " 'almost': 28,\n",
              " 'taste': 17,\n",
              " 'again': 174,\n",
              " 'gazed': 24,\n",
              " 'dublin': 106,\n",
              " 'bay': 23,\n",
              " 'fair': 58,\n",
              " 'oakpale': 1,\n",
              " 'stirring': 4,\n",
              " 'slightly.': 4,\n",
              " 'sea': 79,\n",
              " 'what': 911,\n",
              " 'algy': 2,\n",
              " 'calls': 37,\n",
              " 'great': 127,\n",
              " 'sweet': 71,\n",
              " 'mother': 125,\n",
              " 'snotgreen': 2,\n",
              " 'sea.': 24,\n",
              " 'scrotumtightening': 1,\n",
              " '_epi': 1,\n",
              " 'oinopa': 3,\n",
              " 'ponton_.': 1,\n",
              " 'ah': 60,\n",
              " 'greeks': 5,\n",
              " 'teach': 9,\n",
              " 'you.': 106,\n",
              " 'read': 111,\n",
              " 'them': 574,\n",
              " 'original.': 3,\n",
              " 'thalatta': 1,\n",
              " '_': 2123,\n",
              " 'she': 1142,\n",
              " 'mother.': 14,\n",
              " 'look.': 10,\n",
              " 'stood': 86,\n",
              " 'parapet.': 5,\n",
              " 'leaning': 11,\n",
              " 'water': 97,\n",
              " 'mailboat': 3,\n",
              " 'clearing': 3,\n",
              " 'harbourmouth': 1,\n",
              " 'kingstown.': 2,\n",
              " 'mighty': 11,\n",
              " 'turned': 126,\n",
              " 'abruptly': 4,\n",
              " 'grey': 62,\n",
              " 'searching': 4,\n",
              " 'face.': 48,\n",
              " 'killed': 19,\n",
              " 'why': 162,\n",
              " 'wo': 46,\n",
              " 'let': 203,\n",
              " 'anything': 79,\n",
              " 'someone': 41,\n",
              " 'her': 1679,\n",
              " 'gloomily.': 1,\n",
              " 'could': 353,\n",
              " 'knelt': 13,\n",
              " 'damn': 38,\n",
              " 'when': 543,\n",
              " 'dying': 30,\n",
              " 'asked': 109,\n",
              " 'hyperborean': 1,\n",
              " 'much': 150,\n",
              " 'think': 123,\n",
              " 'begging': 6,\n",
              " 'last': 171,\n",
              " 'breath': 43,\n",
              " 'kneel': 8,\n",
              " 'pray': 34,\n",
              " 'her.': 90,\n",
              " 'refused.': 2,\n",
              " 'something': 162,\n",
              " 'sinister': 5,\n",
              " 'you....': 1,\n",
              " 'lightly': 20,\n",
              " 'farther': 19,\n",
              " 'cheek.': 9,\n",
              " 'tolerant': 1,\n",
              " 'curled': 7,\n",
              " 'lovely': 68,\n",
              " 'mummer': 5,\n",
              " 'murmured': 9,\n",
              " 'loveliest': 1,\n",
              " 'evenly': 3,\n",
              " 'care': 38,\n",
              " 'silence': 23,\n",
              " 'seriously.': 2,\n",
              " 'elbow': 11,\n",
              " 'rested': 7,\n",
              " 'jagged': 1,\n",
              " 'granite': 3,\n",
              " 'palm': 12,\n",
              " 'against': 126,\n",
              " 'brow': 17,\n",
              " 'fraying': 1,\n",
              " 'shiny': 5,\n",
              " 'coat': 25,\n",
              " 'sleeve.': 4,\n",
              " 'pain': 14,\n",
              " 'yet': 69,\n",
              " 'fretted': 2,\n",
              " 'heart.': 16,\n",
              " 'silently': 14,\n",
              " 'dream': 18,\n",
              " 'had': 815,\n",
              " 'after': 404,\n",
              " 'death': 61,\n",
              " 'wasted': 2,\n",
              " 'within': 39,\n",
              " 'brown': 58,\n",
              " 'graveclothes': 2,\n",
              " 'giving': 26,\n",
              " 'odour': 16,\n",
              " 'wax': 10,\n",
              " 'rosewood': 3,\n",
              " 'upon': 131,\n",
              " 'mute': 13,\n",
              " 'reproachful': 2,\n",
              " 'faint': 10,\n",
              " 'wetted': 5,\n",
              " 'ashes.': 7,\n",
              " 'across': 59,\n",
              " 'threadbare': 1,\n",
              " 'cuffedge': 1,\n",
              " 'saw': 150,\n",
              " 'hailed': 3,\n",
              " 'wellfed': 1,\n",
              " 'beside': 45,\n",
              " 'him.': 199,\n",
              " 'skyline': 2,\n",
              " 'dull': 22,\n",
              " 'green': 88,\n",
              " 'mass': 23,\n",
              " 'liquid.': 1,\n",
              " 'china': 8,\n",
              " 'deathbed': 2,\n",
              " 'holding': 37,\n",
              " 'sluggish': 2,\n",
              " 'bile': 2,\n",
              " 'torn': 10,\n",
              " 'rotting': 1,\n",
              " 'liver': 14,\n",
              " 'fits': 6,\n",
              " 'loud': 23,\n",
              " 'groaning': 3,\n",
              " 'vomiting.': 1,\n",
              " 'poor': 165,\n",
              " 'dogsbody': 5,\n",
              " 'kind': 100,\n",
              " 'voice.': 22,\n",
              " 'give': 170,\n",
              " 'shirt': 24,\n",
              " 'few': 74,\n",
              " 'noserags.': 1,\n",
              " 'are': 516,\n",
              " 'secondhand': 5,\n",
              " 'breeks': 1,\n",
              " 'they': 1032,\n",
              " 'fit': 16,\n",
              " 'well': 241,\n",
              " 'enough': 60,\n",
              " 'answered.': 22,\n",
              " 'attacked': 1,\n",
              " 'hollow': 12,\n",
              " 'beneath': 23,\n",
              " 'underlip.': 1,\n",
              " 'contentedly.': 1,\n",
              " 'secondleg': 1,\n",
              " 'should': 84,\n",
              " 'be.': 22,\n",
              " 'knows': 65,\n",
              " 'poxy': 1,\n",
              " 'bowsy': 1,\n",
              " 'left': 153,\n",
              " 'pair': 43,\n",
              " 'stripe': 1,\n",
              " 'grey.': 5,\n",
              " 'll': 221,\n",
              " 'look': 177,\n",
              " 'spiffing': 2,\n",
              " 'them.': 89,\n",
              " 'joking': 4,\n",
              " 'kinch.': 4,\n",
              " 'dressed.': 1,\n",
              " 'wear': 25,\n",
              " 'told': 142,\n",
              " 'mirror.': 6,\n",
              " 'etiquette': 3,\n",
              " 'etiquette.': 2,\n",
              " 'kills': 6,\n",
              " 'trousers.': 9,\n",
              " 'folded': 24,\n",
              " 'neatly': 8,\n",
              " 'stroking': 2,\n",
              " 'palps': 1,\n",
              " 'fingers': 48,\n",
              " 'felt': 60,\n",
              " 'smooth': 9,\n",
              " 'skin.': 7,\n",
              " 'gaze': 31,\n",
              " 'smokeblue': 1,\n",
              " 'mobile': 2,\n",
              " 'eyes.': 53,\n",
              " 'fellow': 124,\n",
              " 'ship': 16,\n",
              " 'says': 402,\n",
              " 'g.': 11,\n",
              " 'p.': 62,\n",
              " 'i.': 52,\n",
              " 'dottyville': 1,\n",
              " 'connolly': 2,\n",
              " 'norman.': 1,\n",
              " 'general': 42,\n",
              " 'paralysis': 2,\n",
              " 'insane': 2,\n",
              " 'swept': 7,\n",
              " 'half': 116,\n",
              " 'circle': 17,\n",
              " 'flash': 10,\n",
              " 'tidings': 4,\n",
              " 'abroad': 5,\n",
              " 'sunlight': 12,\n",
              " 'now': 327,\n",
              " 'radiant': 5,\n",
              " 'curling': 6,\n",
              " 'lips': 61,\n",
              " 'laughed': 29,\n",
              " 'edges': 3,\n",
              " 'glittering': 2,\n",
              " 'teeth.': 13,\n",
              " 'laughter': 24,\n",
              " 'seized': 4,\n",
              " 'wellknit': 1,\n",
              " 'trunk.': 2,\n",
              " 'yourself': 25,\n",
              " 'cleft': 4,\n",
              " 'crooked': 15,\n",
              " 'crack.': 2,\n",
              " 'end.': 14,\n",
              " 'others': 51,\n",
              " 'see': 353,\n",
              " 'me.': 138,\n",
              " 'who': 492,\n",
              " 'chose': 6,\n",
              " 'rid': 7,\n",
              " 'vermin.': 2,\n",
              " 'asks': 5,\n",
              " 'too.': 84,\n",
              " 'pinched': 2,\n",
              " 'skivvy': 1,\n",
              " 'room': 44,\n",
              " 'does': 119,\n",
              " 'right.': 48,\n",
              " 'always': 171,\n",
              " 'keeps': 11,\n",
              " 'plainlooking': 1,\n",
              " 'servants': 6,\n",
              " 'malachi.': 3,\n",
              " 'lead': 11,\n",
              " 'temptation.': 1,\n",
              " 'ursula.': 1,\n",
              " 'brought': 79,\n",
              " 'away': 141,\n",
              " 'peering': 9,\n",
              " 'rage': 3,\n",
              " 'caliban': 2,\n",
              " 'seeing': 30,\n",
              " 'wilde': 8,\n",
              " 'only': 246,\n",
              " 'alive': 11,\n",
              " 'drawing': 16,\n",
              " 'pointing': 14,\n",
              " 'bitterness': 5,\n",
              " 'symbol': 8,\n",
              " 'art.': 2,\n",
              " 'cracked': 10,\n",
              " 'lookingglass': 4,\n",
              " 'servant.': 3,\n",
              " 'suddenly': 34,\n",
              " 'linked': 11,\n",
              " 'arm': 40,\n",
              " 'walked': 74,\n",
              " 'clacking': 3,\n",
              " 'thrust': 13,\n",
              " 'tease': 3,\n",
              " 'kindly.': 3,\n",
              " 'more': 284,\n",
              " 'spirit': 23,\n",
              " 'than': 169,\n",
              " 'any': 189,\n",
              " 'fears': 4,\n",
              " 'lancet': 1,\n",
              " 'fear': 31,\n",
              " 'his.': 11,\n",
              " 'cold': 60,\n",
              " 'steel': 13,\n",
              " 'pen.': 2,\n",
              " 'servant': 9,\n",
              " 'oxy': 1,\n",
              " 'downstairs': 2,\n",
              " 'touch': 37,\n",
              " 'guinea.': 2,\n",
              " 'stinking': 3,\n",
              " 'tin': 12,\n",
              " 'selling': 10,\n",
              " 'jalap': 1,\n",
              " 'zulus': 1,\n",
              " 'or': 947,\n",
              " 'some': 309,\n",
              " 'swindle': 5,\n",
              " 'other.': 17,\n",
              " 'work': 51,\n",
              " 'together': 43,\n",
              " 'might': 176,\n",
              " 'island.': 2,\n",
              " 'cranly': 7,\n",
              " 'arm.': 12,\n",
              " 'having': 115,\n",
              " 'beg': 10,\n",
              " 'swine.': 2,\n",
              " 'one': 681,\n",
              " 'are.': 22,\n",
              " 'trust': 8,\n",
              " 'nose': 52,\n",
              " 'makes': 45,\n",
              " 'noise': 16,\n",
              " 'bring': 45,\n",
              " 'seymour': 9,\n",
              " 'ragging': 2,\n",
              " 'worse': 21,\n",
              " 'clive': 2,\n",
              " 'kempthorpe.': 1,\n",
              " 'young': 177,\n",
              " 'shouts': 7,\n",
              " 'moneyed': 2,\n",
              " 'voices': 23,\n",
              " 'kempthorpe': 1,\n",
              " 'rooms.': 4,\n",
              " 'palefaces': 1,\n",
              " 'their': 717,\n",
              " 'ribs': 6,\n",
              " 'clasping': 4,\n",
              " 'another.': 15,\n",
              " 'shall': 65,\n",
              " 'expire': 1,\n",
              " 'break': 17,\n",
              " 'news': 12,\n",
              " 'aubrey': 2,\n",
              " 'die': 25,\n",
              " 'slit': 4,\n",
              " 'ribbons': 3,\n",
              " 'whipping': 3,\n",
              " 'hops': 1,\n",
              " 'hobbles': 2,\n",
              " 'table': 52,\n",
              " 'trousers': 39,\n",
              " 'heels': 19,\n",
              " 'chased': 3,\n",
              " 'ades': 1,\n",
              " 'magdalen': 1,\n",
              " 'tailor': 7,\n",
              " 'shears.': 1,\n",
              " 'scared': 4,\n",
              " 'calf': 7,\n",
              " 'gilded': 5,\n",
              " 'marmalade.': 1,\n",
              " 'want': 142,\n",
              " 'be': 851,\n",
              " 'debagged': 1,\n",
              " 'play': 42,\n",
              " 'giddy': 7,\n",
              " 'ox': 4,\n",
              " 'open': 87,\n",
              " 'window': 54,\n",
              " 'startling': 1,\n",
              " 'evening': 57,\n",
              " 'quadrangle.': 1,\n",
              " 'deaf': 9,\n",
              " 'gardener': 3,\n",
              " 'aproned': 2,\n",
              " 'masked': 5,\n",
              " 'matthew': 8,\n",
              " 'arnold': 3,\n",
              " 'pushes': 2,\n",
              " 'mower': 1,\n",
              " 'sombre': 3,\n",
              " 'lawn': 10,\n",
              " 'narrowly': 1,\n",
              " 'dancing': 17,\n",
              " 'motes': 1,\n",
              " 'grasshalms.': 2,\n",
              " 'ourselves...': 1,\n",
              " 'paganism...': 1,\n",
              " 'omphalos.': 3,\n",
              " 'nothing': 77,\n",
              " 'wrong': 36,\n",
              " 'except': 21,\n",
              " 'night.': 38,\n",
              " 'impatiently.': 4,\n",
              " 'cough': 7,\n",
              " 'up.': 85,\n",
              " 'quite': 78,\n",
              " 'frank': 8,\n",
              " 'looking': 106,\n",
              " 'blunt': 4,\n",
              " 'cape': 7,\n",
              " 'bray': 3,\n",
              " 'head': 182,\n",
              " 'snout': 5,\n",
              " 'sleeping': 11,\n",
              " 'whale.': 2,\n",
              " 'freed': 3,\n",
              " 'wish': 32,\n",
              " 'remember': 63,\n",
              " 'anything.': 9,\n",
              " 'spoke.': 6,\n",
              " 'wind': 50,\n",
              " 'passed': 91,\n",
              " 'fanning': 13,\n",
              " 'softly': 22,\n",
              " 'uncombed': 2,\n",
              " 'silver': 38,\n",
              " 'points': 36,\n",
              " 'anxiety': 2,\n",
              " 'depressed': 1,\n",
              " 'own': 139,\n",
              " 'first': 248,\n",
              " 'day': 207,\n",
              " 'house': 138,\n",
              " 'quickly': 42,\n",
              " 'ideas': 6,\n",
              " 'sensations.': 1,\n",
              " 'happened': 18,\n",
              " 'making': 45,\n",
              " 'tea': 53,\n",
              " 'landing': 5,\n",
              " 'hot': 45,\n",
              " 'water.': 21,\n",
              " 'visitor': 2,\n",
              " 'drawingroom.': 1,\n",
              " 'room.': 6,\n",
              " 'did': 461,\n",
              " 'say': 219,\n",
              " '_o': 2,\n",
              " 'whose': 43,\n",
              " 'beastly': 6,\n",
              " 'dead._': 1,\n",
              " 'flush': 8,\n",
              " 'seem': 12,\n",
              " 'younger': 9,\n",
              " 'engaging': 2,\n",
              " 'rose': 52,\n",
              " 'harm': 14,\n",
              " 'shook': 22,\n",
              " 'constraint': 1,\n",
              " 'nervously.': 3,\n",
              " 'yours': 16,\n",
              " 'die.': 9,\n",
              " 'pop': 8,\n",
              " 'every': 140,\n",
              " 'mater': 8,\n",
              " 'richmond': 7,\n",
              " 'cut': 46,\n",
              " 'tripes': 3,\n",
              " 'dissectingroom.': 1,\n",
              " 'thing': 180,\n",
              " 'else.': 10,\n",
              " 'simply': 50,\n",
              " 'matter.': 6,\n",
              " 'would': 436,\n",
              " 'cursed': 8,\n",
              " 'strain': 8,\n",
              " 'injected': 2,\n",
              " 'way.': 39,\n",
              " 'beastly.': 1,\n",
              " 'cerebral': 2,\n",
              " 'lobes': 1,\n",
              " 'functioning.': 1,\n",
              " 'doctor': 23,\n",
              " 'sir': 119,\n",
              " 'peter': 22,\n",
              " 'teazle': 1,\n",
              " 'picks': 6,\n",
              " 'buttercups': 1,\n",
              " 'quilt.': 1,\n",
              " 'humour': 6,\n",
              " 'till': 133,\n",
              " 'over.': 27,\n",
              " 'crossed': 25,\n",
              " 'sulk': 1,\n",
              " 'whinge': 1,\n",
              " 'hired': 2,\n",
              " 'lalouette': 1,\n",
              " 'is.': 142,\n",
              " 'suppose': 101,\n",
              " 'it.': 228,\n",
              " 'mean': 63,\n",
              " 'offend': 2,\n",
              " 'memory': 28,\n",
              " 'spoken': 16,\n",
              " 'boldness.': 2,\n",
              " 'shielding': 1,\n",
              " 'gaping': 10,\n",
              " 'wounds': 3,\n",
              " 'words': 91,\n",
              " 'heart': 104,\n",
              " 'very': 218,\n",
              " 'thinking': 39,\n",
              " 'offence': 8,\n",
              " 'asked.': 46,\n",
              " 'swung': 9,\n",
              " 'heel.': 2,\n",
              " 'impossible': 5,\n",
              " 'person': 47,\n",
              " 'post': 19,\n",
              " 'calm': 10,\n",
              " 'headland.': 1,\n",
              " 'headland': 3,\n",
              " 'grew': 10,\n",
              " 'dim.': 1,\n",
              " 'pulses': 2,\n",
              " 'beating': 7,\n",
              " 'veiling': 2,\n",
              " 'fever': 7,\n",
              " 'cheeks.': 4,\n",
              " 'loudly': 17,\n",
              " 'coming': 107,\n",
              " 'offences': 1,\n",
              " 'chuck': 4,\n",
              " 'loyola': 2,\n",
              " 'down.': 35,\n",
              " 'sassenach': 2,\n",
              " 'wants': 43,\n",
              " 'rashers.': 1,\n",
              " 'moment': 62,\n",
              " 'level': 12,\n",
              " 'roof': 4,\n",
              " 'mope': 1,\n",
              " 'inconsequent.': 1,\n",
              " 'moody': 3,\n",
              " 'brooding.': 1,\n",
              " 'vanished': 6,\n",
              " 'drone': 2,\n",
              " 'descending': 4,\n",
              " 'boomed': 3,\n",
              " 'no': 587,\n",
              " 'turn': 61,\n",
              " 'brood': 7,\n",
              " 'bitter': 11,\n",
              " 'mystery': 10,\n",
              " 'fergus': 4,\n",
              " 'rules': 8,\n",
              " 'brazen': 6,\n",
              " 'cars.': 1,\n",
              " 'woodshadows': 1,\n",
              " 'floated': 8,\n",
              " 'peace': 17,\n",
              " 'seaward': 2,\n",
              " 'gazed.': 1,\n",
              " 'inshore': 1,\n",
              " 'whitened': 2,\n",
              " 'spurned': 5,\n",
              " 'lightshod': 1,\n",
              " 'hurrying': 4,\n",
              " 'feet.': 12,\n",
              " 'breast': 23,\n",
              " 'dim': 5,\n",
              " 'twining': 5,\n",
              " 'stresses': 1,\n",
              " 'two.': 9,\n",
              " 'plucking': 3,\n",
              " 'harpstrings': 1,\n",
              " 'merging': 1,\n",
              " 'chords.': 6,\n",
              " 'wavewhite': 1,\n",
              " 'wedded': 2,\n",
              " 'shimmering': 3,\n",
              " 'tide.': 1,\n",
              " 'cloud': 13,\n",
              " 'cover': 12,\n",
              " 'sun': 61,\n",
              " 'slowly': 62,\n",
              " 'wholly': 4,\n",
              " 'shadowing': 2,\n",
              " 'deeper': 2,\n",
              " 'green.': 7,\n",
              " 'waters.': 8,\n",
              " 'song': 25,\n",
              " 'sang': 31,\n",
              " 'alone': 36,\n",
              " 'door': 108,\n",
              " 'wanted': 63,\n",
              " 'hear': 101,\n",
              " 'music.': 9,\n",
              " 'silent': 44,\n",
              " 'awe': 4,\n",
              " 'pity': 30,\n",
              " 'bedside.': 1,\n",
              " 'crying': 10,\n",
              " 'wretched': 6,\n",
              " 'bed.': 21,\n",
              " 'mystery.': 3,\n",
              " 'secrets': 11,\n",
              " 'featherfans': 1,\n",
              " 'tasselled': 3,\n",
              " 'dancecards': 1,\n",
              " 'powdered': 5,\n",
              " 'musk': 1,\n",
              " 'gaud': 1,\n",
              " 'amber': 3,\n",
              " 'beads': 2,\n",
              " 'locked': 12,\n",
              " 'drawer.': 4,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[5234]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-9-FcMcaGdVb",
        "outputId": "b59563a2-c3f8-4d79-e84d-bb37318e4f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goggles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(corpus, vocab, batch_size):\n",
        "    data = []                                                   \n",
        "    for sent in corpus:                                      \n",
        "        tokens = sent.split()\n",
        "        tokens.append(\"<eos>\")\n",
        "        temptokens = []\n",
        "        for word in tokens:\n",
        "          try:\n",
        "            if word != \"<eos>\" and word_count[word] >= 3:\n",
        "                    temptokens.append(vocab[word])\n",
        "            else:\n",
        "                temptokens.append(vocab[\"<unk>\"]) \n",
        "          except KeyError:\n",
        "              temptokens.append(vocab[\"<unk>\"])\n",
        "        data.extend(temptokens)   \n",
        "    data = torch.LongTensor(data)                                 \n",
        "    num_batches = data.shape[0] // batch_size \n",
        "    data = data[:num_batches * batch_size]                       \n",
        "    data = data.view(batch_size, num_batches)          \n",
        "    return data\n"
      ],
      "metadata": {
        "id": "C2UXbVijGfsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = get_data(train_data, vocab_dict, 128)\n",
        "dev_data = get_data(dev_data, vocab_dict, 128)\n",
        "test_data = get_data(test_data, vocab_dict, 128)\n"
      ],
      "metadata": {
        "id": "2i2IHabdGhZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, \n",
        "                tie_weights):\n",
        "                \n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, \n",
        "                    dropout=dropout_rate, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "        if tie_weights:\n",
        "            assert embedding_dim == hidden_dim, 'cannot tie, check dims'\n",
        "            self.embedding.weight = self.fc.weight\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, src, hidden):\n",
        "        embedding = self.dropout(self.embedding(src))\n",
        "        output, hidden = self.lstm(embedding, hidden)          \n",
        "        output = self.dropout(output) \n",
        "        prediction = self.fc(output)\n",
        "        return prediction, hidden\n",
        "    \n",
        "    def init_weights(self):\n",
        "        init_range_emb = 0.1\n",
        "        init_range_other = 1/math.sqrt(self.hidden_dim)\n",
        "        self.embedding.weight.data.uniform_(-init_range_emb, init_range_emb)\n",
        "        self.fc.weight.data.uniform_(-init_range_other, init_range_other)\n",
        "        self.fc.bias.data.zero_()\n",
        "        for i in range(self.num_layers):\n",
        "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.embedding_dim,\n",
        "                    self.hidden_dim).uniform_(-init_range_other, init_range_other) \n",
        "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.hidden_dim, \n",
        "                    self.hidden_dim).uniform_(-init_range_other, init_range_other) \n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return hidden, cell\n",
        "    \n",
        "    def detach_hidden(self, hidden):\n",
        "        hidden, cell = hidden\n",
        "        hidden = hidden.detach()\n",
        "        cell = cell.detach()\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "jM7q4rsJGkzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_dict)\n",
        "embedding_dim = 1150             # 400 in the paper\n",
        "hidden_dim = 1150                # 1150 in the paper\n",
        "num_layers = 2                   # 3 in the paper\n",
        "dropout_rate = 0.5              \n",
        "tie_weights = True                  \n",
        "lr = 1e-3  "
      ],
      "metadata": {
        "id": "uob4ebvoGnLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {num_params:,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy3xN9OWGpgc",
        "outputId": "746f4c1c-dbb6-41d9-9f8b-80afae8106d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 42,694,043 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, seq_len, num_batches, idx):\n",
        "    src = data[:, idx:idx+seq_len]                   \n",
        "    target = data[:, idx+1:idx+seq_len+1]             \n",
        "    return src, target\n"
      ],
      "metadata": {
        "id": "aqissYbiGrdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    # drop all batches that are not a multiple of seq_len\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "    \n",
        "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):  # The last batch can't be a src\n",
        "        optimizer.zero_grad()\n",
        "        hidden = model.detach_hidden(hidden)\n",
        "\n",
        "        src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "        src, target = src.to(device), target.to(device)\n",
        "        batch_size = src.shape[0]\n",
        "        prediction, hidden = model(src, hidden)               \n",
        "\n",
        "        prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
        "        target = target.reshape(-1)\n",
        "        loss = criterion(prediction, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / num_batches\n"
      ],
      "metadata": {
        "id": "4jF3L181GvEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, hidden = model(src, hidden)\n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / num_batches"
      ],
      "metadata": {
        "id": "6d2ViZwCGx0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC_Ai7FOFMdn",
        "outputId": "4c42b96d-067f-40d0-9674-096879dec6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t0 Train Perplexity: 868.115\n",
            "\t0 Valid Perplexity: 377.119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t1 Train Perplexity: 451.417\n",
            "\t1 Valid Perplexity: 326.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t2 Train Perplexity: 409.413\n",
            "\t2 Valid Perplexity: 309.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t3 Train Perplexity: 374.239\n",
            "\t3 Valid Perplexity: 295.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t4 Train Perplexity: 333.837\n",
            "\t4 Valid Perplexity: 269.115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t5 Train Perplexity: 293.663\n",
            "\t5 Valid Perplexity: 257.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t6 Train Perplexity: 261.657\n",
            "\t6 Valid Perplexity: 246.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t7 Train Perplexity: 232.933\n",
            "\t7 Valid Perplexity: 235.730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t8 Train Perplexity: 211.661\n",
            "\t8 Valid Perplexity: 229.571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t9 Train Perplexity: 193.443\n",
            "\t9 Valid Perplexity: 227.291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t10 Train Perplexity: 178.252\n",
            "\t10 Valid Perplexity: 223.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t11 Train Perplexity: 165.532\n",
            "\t11 Valid Perplexity: 224.953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t12 Train Perplexity: 152.322\n",
            "\t12 Valid Perplexity: 223.156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t13 Train Perplexity: 144.399\n",
            "\t13 Valid Perplexity: 222.999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t14 Train Perplexity: 137.772\n",
            "\t14 Valid Perplexity: 224.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t15 Train Perplexity: 131.011\n",
            "\t15 Valid Perplexity: 226.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t16 Train Perplexity: 128.335\n",
            "\t16 Valid Perplexity: 225.374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t17 Train Perplexity: 125.184\n",
            "\t17 Valid Perplexity: 226.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t18 Train Perplexity: 124.086\n",
            "\t18 Valid Perplexity: 226.154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t19 Train Perplexity: 123.808\n",
            "\t19 Valid Perplexity: 226.318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t20 Train Perplexity: 123.272\n",
            "\t20 Valid Perplexity: 226.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t21 Train Perplexity: 123.390\n",
            "\t21 Valid Perplexity: 226.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t22 Train Perplexity: 123.191\n",
            "\t22 Valid Perplexity: 226.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t23 Train Perplexity: 123.101\n",
            "\t23 Valid Perplexity: 226.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t24 Train Perplexity: 123.200\n",
            "\t24 Valid Perplexity: 226.509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t25 Train Perplexity: 123.140\n",
            "\t25 Valid Perplexity: 226.509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t26 Train Perplexity: 122.739\n",
            "\t26 Valid Perplexity: 226.510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t27 Train Perplexity: 123.175\n",
            "\t27 Valid Perplexity: 226.510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t28 Train Perplexity: 123.036\n",
            "\t28 Valid Perplexity: 226.510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t29 Train Perplexity: 122.759\n",
            "\t29 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t30 Train Perplexity: 123.147\n",
            "\t30 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t31 Train Perplexity: 123.191\n",
            "\t31 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t32 Train Perplexity: 123.037\n",
            "\t32 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t33 Train Perplexity: 122.976\n",
            "\t33 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t34 Train Perplexity: 123.399\n",
            "\t34 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t35 Train Perplexity: 123.223\n",
            "\t35 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t36 Train Perplexity: 123.040\n",
            "\t36 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t37 Train Perplexity: 123.103\n",
            "\t37 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t38 Train Perplexity: 122.857\n",
            "\t38 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t39 Train Perplexity: 122.861\n",
            "\t39 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t40 Train Perplexity: 123.147\n",
            "\t40 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t41 Train Perplexity: 123.187\n",
            "\t41 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t42 Train Perplexity: 123.188\n",
            "\t42 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t43 Train Perplexity: 123.258\n",
            "\t43 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t44 Train Perplexity: 123.092\n",
            "\t44 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t45 Train Perplexity: 123.147\n",
            "\t45 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t46 Train Perplexity: 123.017\n",
            "\t46 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t47 Train Perplexity: 123.018\n",
            "\t47 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t48 Train Perplexity: 123.129\n",
            "\t48 Valid Perplexity: 226.511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t49 Train Perplexity: 123.288\n",
            "\t49 Valid Perplexity: 226.511\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 50\n",
        "seq_len = 50\n",
        "clip = 0.25\n",
        "saved = False\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n",
        "if saved:\n",
        "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "    test_loss = evaluate(model, test_data, criterion, 128, seq_len, device)\n",
        "    print(f'Test Perplexity: {math.exp(test_loss):.3f}')\n",
        "else:\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train(model, train_data, optimizer, criterion, \n",
        "                    128, seq_len, clip, device)\n",
        "        valid_loss = evaluate(model, dev_data, criterion, 128, \n",
        "                    seq_len, device)\n",
        "        \n",
        "        lr_scheduler.step(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
        "\n",
        "        print(f'\\t{epoch} Train Perplexity: {math.exp(train_loss):.3f}')\n",
        "        print(f'\\t{epoch} Valid Perplexity: {math.exp(valid_loss):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 50\n",
        "seq_len = 50\n",
        "clip = 0.25\n",
        "saved = True\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n",
        "if saved:\n",
        "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "    test_loss = evaluate(model, test_data, criterion, 128, seq_len, device)\n",
        "    print(f'Test Perplexity: {math.exp(test_loss):.3f}')\n",
        "    import json\n",
        "\n",
        "    with open(f\"ptvocab{math.exp(test_loss):.3f}.json\", \"w\") as f:\n",
        "        json.dump(vocab_dict, f)\n",
        "\n",
        "    with open(f\"word_count{math.exp(test_loss):.3f}.json\", \"w\") as f:\n",
        "        json.dump(word_count, f)\n",
        "\n",
        "\n",
        "else:\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train(model, train_data, optimizer, criterion, \n",
        "                    128, seq_len, clip, device)\n",
        "        valid_loss = evaluate(model, dev_data, criterion, 128, \n",
        "                    seq_len, device)\n",
        "        \n",
        "        lr_scheduler.step(valid_loss)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
        "\n",
        "        print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
        "        print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZSudU64F8C3",
        "outputId": "d86b4959-1798-4bca-9eac-af43fda0c09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Perplexity: 277.126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blPdFMWoF7oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perp(data, vocab_dict):\n",
        "    data = clean_text(data)\n",
        "    data = data.split(\". \")\n",
        "    data = get_data(data, vocab_dict, 16)\n",
        "    print(data)\n",
        "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "    test_loss = evaluate(model, data, criterion, 16, 1, device)\n",
        "    print(test_loss)\n",
        "    print(f'Test Perplexity: {math.exp(test_loss):.3f}')"
      ],
      "metadata": {
        "id": "WZjc5ShTFSsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ptvocab277.126.json\", \"r\") as f:\n",
        "  import json\n",
        "  vocab_dict = json.load(f)\n",
        "\n",
        "with open(\"word_count277.126.json\", \"r\") as f:\n",
        "  import json\n",
        "  word_count = json.load(f)\n",
        "\n",
        "calculate_perp(\"I am is Bhanuj. Bhanuj is, good. one new good word. We're careful about orange ping pong balls because people might think they're fruit. She cried diamonds. Getting up at dawn is for the birds. The beach was crowded with snow leopards.\", vocab_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA_pJ_RM66Y_",
        "outputId": "75d394fe-f446-4b00-8ec5-23d1a1b1aadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11169, 16356, 16803],\n",
            "        [13031, 13031, 13031],\n",
            "        [16803,  9999, 13031],\n",
            "        [15553,  2516,  9999],\n",
            "        [ 7663, 13031, 10178],\n",
            "        [ 8116,  1458, 12267],\n",
            "        [ 4128, 13031, 13031],\n",
            "        [ 7553,  6970,  4605],\n",
            "        [15353,  4200,  7865],\n",
            "        [ 8116, 10499, 13031],\n",
            "        [18392, 14781, 12606],\n",
            "        [13031,  8733,  8400],\n",
            "        [12901,  7064, 16803],\n",
            "        [18403,  5319,  5286],\n",
            "        [13031,  5319,  6832],\n",
            "        [10736, 13972,  6390]])\n",
            "3.699110190073649\n",
            "Test Perplexity: 40.411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4Sh2Jlf7Bgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}